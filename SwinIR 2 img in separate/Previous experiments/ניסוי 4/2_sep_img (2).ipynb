{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0ZEjrXxNmQV"
      },
      "source": [
        "# init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-RoiR68DKvGV",
        "outputId": "e25c40d6-2915-431c-894d-a3197af79fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c4KAOGuEEdhe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torchvision.transforms.functional as TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbZ45kXgEoc-",
        "outputId": "0ff68a0a-bf19-473a-d664-1cbeb174a639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "base_folder = '/content/drive/My Drive/ONLY_TIF'\n",
        "csv_path = '/content/drive/My Drive/superres_triplets.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKFwD2UjFe_J"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "for col in ['goes1_path', 'goes2_path', 'viirs_path']:\n",
        "    df[col] = df[col].apply(lambda x: os.path.join(base_folder, x))\n",
        "\n",
        "df.to_csv(csv_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OOzb6WbNrwr"
      },
      "source": [
        "# dataset+loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yp4yvnIJFsTb"
      },
      "outputs": [],
      "source": [
        "class SatelliteTripletDataset(Dataset):\n",
        "    def __init__(self, csv_file, json_range_path=\"radiance_visualization_ranges.json\"):\n",
        "        self.data_info = pd.read_csv(csv_file)\n",
        "\n",
        "        with open(json_range_path, \"r\") as f:\n",
        "            self.global_ranges = json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        record = self.data_info.iloc[idx]\n",
        "        goes1 = self.load_raw_radiance(record['goes1_path'])\n",
        "        goes2 = self.load_raw_radiance(record['goes2_path'])\n",
        "        viirs = self.load_raw_radiance(record['viirs_path'])\n",
        "        return (goes1, goes2), viirs\n",
        "\n",
        "    def load_raw_radiance(self, path):\n",
        "        filename = os.path.basename(path).lower()\n",
        "        is_viirs = \"viirs\" in filename or \"combined_clip\" in filename\n",
        "        sensor_type = \"VIIRS\" if is_viirs else \"GOES\"\n",
        "        band_index = 1 if is_viirs else 7\n",
        "\n",
        "        with rasterio.open(path) as src:\n",
        "            if src.count < band_index:\n",
        "                raise ValueError(f\"{path} does not contain band {band_index}\")\n",
        "            image = src.read(band_index).astype(np.float32)\n",
        "\n",
        "        # Handle NaN/Inf values\n",
        "        mask = ~(np.isnan(image) | np.isinf(image))\n",
        "        if not np.any(mask):\n",
        "            image = np.zeros_like(image)\n",
        "        else:\n",
        "            mean_val = image[mask].mean()\n",
        "            image = np.where(mask, image, mean_val)\n",
        "\n",
        "        # 🔁 Use global clipping range from JSON\n",
        "        p_low = self.global_ranges[sensor_type][\"p2\"]\n",
        "        p_high = self.global_ranges[sensor_type][\"p98\"]\n",
        "        image = np.clip(image, p_low, p_high)\n",
        "        image = (image - p_low) / (p_high - p_low)\n",
        "\n",
        "        return torch.from_numpy(image).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5PSrVc18F3WC"
      },
      "outputs": [],
      "source": [
        "class SatelliteDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, csv_file, batch_size=4, num_workers=0, percentile_range=(0.5, 99.5)):\n",
        "        super().__init__()\n",
        "        self.csv_file = csv_file\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.percentile_range = percentile_range\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = SatelliteTripletDataset(\n",
        "            csv_file=self.csv_file,\n",
        "            json_range_path=\"/content/radiance_visualization_ranges.json\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RHqZDRPmMOIr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7-R6rZhNvs3"
      },
      "source": [
        "# external liberery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L3_1HOshICbp",
        "outputId": "7631efe6-16f0-453c-d8e6-fbb7a4c808a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SwinIR' already exists and is not an empty directory.\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# sys.path.append(\"C:/Users/97254/OneDrive - post.bgu.ac.il/Desktop/code4finalproj/SwinIR-main\")\n",
        "# Clone the repo\n",
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "sys.path.append('/content/SwinIR')\n",
        "\n",
        "# Manually install necessary dependencies\n",
        "!pip install timm einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-P24DfpGRis",
        "outputId": "875cbcdb-a79b-4f5a-b573-0cc4488ad2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# Now you're safe to import\n",
        "from models.network_swinir import SwinIR\n",
        "\n",
        "model = SwinIR(\n",
        "    upscale=4,            # 100x4 = 400 → desired upscale\n",
        "    in_chans=1,           # GOES1 + GOES2 = 2 input channels\n",
        "    img_size=100,         # patch input size\n",
        "    window_size=25,        # usually 8 or 7 works fine\n",
        "    img_range=1.,\n",
        "    depths=[3,3,3,3,3,3],\n",
        "    # depths=[2,2,2,2,2,2],\n",
        "    embed_dim=180,\n",
        "    # embed_dim=64,\n",
        "    # num_heads=[8,8,8,8,8,8],\n",
        "    num_heads=[6,6,6,6,6,6],\n",
        "    mlp_ratio=2,\n",
        "    # upsampler='nearest+conv',\n",
        "    upsampler='convtranspose',\n",
        "    resi_connection='3conv'\n",
        "    # out_chans=1\n",
        "    # <<< set to 1 for single-channel output\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfcs3mYeN0Gc"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DpwLlWUniVgQ"
      },
      "outputs": [],
      "source": [
        "class SuperResolutionModule(pl.LightningModule):\n",
        "    def __init__(self, model, lr=1e-4):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.L1Loss()\n",
        "        self.lr = lr\n",
        "\n",
        "        with open(\"/content/radiance_visualization_ranges.json\", \"r\") as f:\n",
        "            self.ranges = json.load(f)\n",
        "\n",
        "        self.goes1_path = \"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo16.tif\"\n",
        "        self.goes2_path = \"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo17.tif\"\n",
        "        self.viirs_path = \"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/combined_clip.tif\"\n",
        "\n",
        "    def forward(self, goes1, goes2):\n",
        "        out1 = self.model(goes1)  # Each has shape [B, 1, H, W]\n",
        "        out2 = self.model(goes2)\n",
        "        return out1, out2\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (goes1, goes2), viirs = batch\n",
        "        # print(\"in\", goes1.min(), goes1.max())\n",
        "        viirs = viirs.float()\n",
        "        # print(\"VIIRS min/max:\", viirs.min().item(), viirs.max().item())\n",
        "\n",
        "        out1, out2 = self(goes1, goes2)\n",
        "        # print(\"out\" , out1.min(), out1.max())\n",
        "\n",
        "        out1 = out1.clamp(0., 1.)\n",
        "        out2 = out2.clamp(0., 1.)\n",
        "\n",
        "        # print(\"out after norm\" , out1.min(), out1.max())\n",
        "\n",
        "\n",
        "        loss1 = self.criterion(out1, viirs)\n",
        "        loss2 = self.criterion(out2, viirs)\n",
        "        loss = (loss1 + loss2) / 2\n",
        "\n",
        "        psnr1 = self.compute_psnr(out1, viirs)\n",
        "        psnr2 = self.compute_psnr(out2, viirs)\n",
        "        avg_psnr = (psnr1 + psnr2) / 2\n",
        "\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_psnr', avg_psnr, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        (goes1, goes2), viirs = batch\n",
        "        viirs = viirs.float()\n",
        "\n",
        "        out1, out2 = self(goes1, goes2)\n",
        "        loss1 = self.criterion(out1, viirs)\n",
        "        loss2 = self.criterion(out2, viirs)\n",
        "        val_loss = (loss1 + loss2) / 2\n",
        "\n",
        "        psnr1 = self.compute_psnr(out1, viirs)\n",
        "        psnr2 = self.compute_psnr(out2, viirs)\n",
        "        avg_psnr = (psnr1 + psnr2) / 2\n",
        "\n",
        "        self.log('val_loss', val_loss, prog_bar=True)\n",
        "        self.log('val_psnr', avg_psnr, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "\n",
        "    # def on_train_epoch_end(self):\n",
        "    #   (goes1, goes2), viirs = self.example_batch\n",
        "\n",
        "    #   self.eval()\n",
        "    #   with torch.no_grad():\n",
        "    #       # inputs = torch.cat((goes1, goes2), dim=1).float().to(self.device)\n",
        "    #       # output = self(inputs)\n",
        "    #       output = self(goes1.to(self.device), goes2.to(self.device))\n",
        "    #       output = F.interpolate(output, size=viirs.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "    #   inp1 = goes1[0][0].cpu().numpy()\n",
        "    #   inp2 = goes2[0][0].cpu().numpy()\n",
        "    #   tgt = viirs[0][0].cpu().numpy()\n",
        "    #   out = output[0][0].cpu().numpy()\n",
        "\n",
        "    #   fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
        "    #   axs[0].imshow(inp1, cmap='gray'); axs[0].set_title('GOES 1')\n",
        "    #   axs[1].imshow(inp2, cmap='gray'); axs[1].set_title('GOES 2')\n",
        "    #   axs[2].imshow(tgt, cmap='gray'); axs[2].set_title('VIIRS Target')\n",
        "    #   axs[3].imshow(out, cmap='gray'); axs[3].set_title('Model Output')\n",
        "    #   fig.suptitle(f'Epoch {self.current_epoch+1} - Triplet Visualization', fontsize=14)\n",
        "\n",
        "    #   for ax in axs: ax.axis('off')\n",
        "    #   plt.tight_layout()\n",
        "    #   plt.show()\n",
        "\n",
        "\n",
        "    def on_train_start(self):\n",
        "      goes1 = self.load_radiance(self.goes1_path)\n",
        "      goes2 = self.load_radiance(self.goes2_path)\n",
        "      viirs  = self.load_radiance(self.viirs_path)\n",
        "      # Add batch dimension [1, 1, H, W]\n",
        "      self.example_batch = ((goes1.unsqueeze(0), goes2.unsqueeze(0)), viirs.unsqueeze(0))\n",
        "\n",
        "\n",
        "    def load_radiance(self, path, band=1):\n",
        "        with rasterio.open(path) as src:\n",
        "            img = src.read(band).astype(np.float32)\n",
        "            mask = ~(np.isnan(img) | np.isinf(img))\n",
        "            if mask.any():\n",
        "                img = np.where(mask, img, img[mask].mean())\n",
        "            else:\n",
        "                img = np.zeros_like(img)\n",
        "            if \"viirs\" in path.lower():\n",
        "                p2, p98 = self.ranges[\"VIIRS\"][\"p2\"], self.ranges[\"VIIRS\"][\"p98\"]\n",
        "            else:\n",
        "                p2, p98 = self.ranges[\"GOES\"][\"p2\"], self.ranges[\"GOES\"][\"p98\"]\n",
        "\n",
        "            img = np.clip(img, p2, p98)\n",
        "            img = (img - p2) / (p98 - p2)\n",
        "            return torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "\n",
        "\n",
        "    def compute_psnr(self, output, target, max_val=1.0):\n",
        "      mse = F.mse_loss(output, target)\n",
        "      if mse == 0:\n",
        "          return torch.tensor(100.0)  # Perfect match\n",
        "      psnr = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
        "      return psnr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8P7doAvN2UT"
      },
      "source": [
        "#callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xKSkRRjzL6J4"
      },
      "outputs": [],
      "source": [
        "class PSNRValidationCallback(Callback):\n",
        "    \"\"\"\n",
        "    Compute corrected PSNR (Kelvin metric) on a fixed month of triplets.\n",
        "    * uses the same helpers as the baseline script              (already defined)\n",
        "    * model gets raw GOES‑16 / GOES‑17(18) images (no bicubic up‑scale)\n",
        "    * VIIRS GT and model prediction are both high‑res → same shape\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    def __init__(self, vis_callback, val_month_dir, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.vis_callback   = vis_callback\n",
        "        self.val_month_dir  = val_month_dir\n",
        "        self.every_n_epochs = every_n_epochs\n",
        "\n",
        "        # read radiometric ranges once\n",
        "        with open(\"/content/radiance_visualization_ranges.json\") as f:\n",
        "            rng = json.load(f)\n",
        "        self.vi_min = rng[\"VIIRS\"][\"p2\"]\n",
        "        self.vi_rng = rng[\"VIIRS\"][\"p98\"] - self.vi_min\n",
        "\n",
        "        # collect (goes1, goes2, viirs) triplets once\n",
        "        self.triplets = self._collect_triplets(val_month_dir)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    @staticmethod\n",
        "    def _collect_triplets(root):\n",
        "        out = []\n",
        "        for cur, _, files in os.walk(root):\n",
        "            files = [f for f in files if f.lower().endswith(\".tif\")]\n",
        "            if not files:\n",
        "                continue\n",
        "            g1 = g2 = v = None\n",
        "            for f in files:\n",
        "                p  = os.path.join(cur, f)\n",
        "                lf = f.lower()\n",
        "                if \"geo16\" in lf:\n",
        "                    g1 = p\n",
        "                elif \"geo17\" in lf or (\"geo18\" in lf and g2 is None):\n",
        "                    g2 = p\n",
        "                elif \"combined\" in lf or \"viirs\" in lf:\n",
        "                    v  = p\n",
        "            if g1 and g2 and v:\n",
        "                out.append((g1, g2, v))\n",
        "        return out\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    @staticmethod\n",
        "    def _load_band(path):\n",
        "        with rasterio.open(path) as src:\n",
        "            img = src.read(1).astype(np.float32)\n",
        "        m = ~(np.isnan(img) | np.isinf(img))\n",
        "        img = np.where(m, img, img[m].mean() if m.any() else 0.0)\n",
        "\n",
        "        # נירמול ל־[0,1]\n",
        "        is_viirs = \"viirs\" in path.lower() or \"combined\" in path.lower()\n",
        "        with open(\"/content/radiance_visualization_ranges.json\",\"r\") as f:\n",
        "            ranges = json.load(f)\n",
        "        rng = ranges[\"VIIRS\"] if is_viirs else ranges[\"GOES\"]\n",
        "\n",
        "        img = np.clip(img, rng[\"p2\"], rng[\"p98\"])\n",
        "        img = (img - rng[\"p2\"]) / (rng[\"p98\"] - rng[\"p2\"])\n",
        "        return img\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def cpsnr(gt: np.ndarray, pred: np.ndarray, mask: np.ndarray) -> float:\n",
        "        \"\"\"Corrected PSNR (Kelvin): brightness‑bias + clear‑pixel mask.\"\"\"\n",
        "        diff = (gt - pred) * mask\n",
        "        b    = diff.sum() / (mask.sum() + 1e-8)                 # brightness bias\n",
        "        cmse = ((gt - pred + b) ** 2 * mask).sum() / (mask.sum() + 1e-8)\n",
        "        return -10.0 * np.log10(cmse + 1e-8)\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch = trainer.current_epoch\n",
        "        if (epoch + 1) % self.every_n_epochs:\n",
        "            return\n",
        "        psnrs1 = []\n",
        "        psnrs2 = []\n",
        "\n",
        "        for i, (g1_path, g2_path, v_path) in enumerate(self.triplets):\n",
        "            print(f\"→ [{i}] {os.path.basename(g1_path)}, {os.path.basename(g2_path)}, {os.path.basename(v_path)}\")\n",
        "\n",
        "            g1 = self._load_band(g1_path)\n",
        "            g2 = self._load_band(g2_path)\n",
        "            vi = self._load_band(v_path)\n",
        "\n",
        "\n",
        "            # forward pass – model expects raw GOES (low-res) inputs\n",
        "            with torch.no_grad():\n",
        "                pred1, pred2 = pl_module(\n",
        "                    torch.from_numpy(g1)[None, None].to(pl_module.device),\n",
        "                    torch.from_numpy(g2)[None, None].to(pl_module.device)\n",
        "                )\n",
        "            pred1 = pred1.squeeze().detach().cpu().numpy()\n",
        "            pred2 = pred2.squeeze().detach().cpu().numpy()\n",
        "\n",
        "            # Normalize ground truth and predictions to [0,1]\n",
        "            vi_n     = np.clip((vi    - self.vi_min) / self.vi_rng, 0, 1)\n",
        "            pred1_n  = np.clip((pred1 - self.vi_min) / self.vi_rng, 0, 1)\n",
        "            pred2_n  = np.clip((pred2 - self.vi_min) / self.vi_rng, 0, 1)\n",
        "\n",
        "            # Compute PSNR for each prediction\n",
        "            psnr1 = self.cpsnr(vi_n, pred1_n, np.ones_like(vi_n))\n",
        "            psnr2 = self.cpsnr(vi_n, pred2_n, np.ones_like(vi_n))\n",
        "\n",
        "            # Store results\n",
        "            psnrs1.append(psnr1)\n",
        "            psnrs2.append(psnr2)\n",
        "\n",
        "\n",
        "        mean_psnr1 = float(np.mean(psnrs1))\n",
        "        mean_psnr2 = float(np.mean(psnrs2))\n",
        "        mean_psnr_avg = (mean_psnr1 + mean_psnr2) / 2\n",
        "\n",
        "        if not hasattr(pl_module, \"psnr_scores_goes1\"):\n",
        "            pl_module.psnr_scores_goes1 = []\n",
        "            pl_module.psnr_scores_goes2 = []\n",
        "            pl_module.psnr_scores_avg   = []\n",
        "\n",
        "        pl_module.psnr_scores_goes1.append(mean_psnr1)\n",
        "        pl_module.psnr_scores_goes2.append(mean_psnr2)\n",
        "        pl_module.psnr_scores_avg.append(mean_psnr_avg)\n",
        "\n",
        "        print(f\"\\n📈 Epoch {epoch:03d} — GOES-1 PSNR: {mean_psnr1:.2f} | GOES-2 PSNR: {mean_psnr2:.2f} | Avg: {mean_psnr_avg:.2f} dB\\n\")\n",
        "\n",
        "        # save curve\n",
        "        plot_path = os.path.join(self.vis_callback.output_dir,\n",
        "                                f\"psnr_curve_epoch_{epoch:03d}.png\")\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(pl_module.psnr_scores_goes1, label=\"GOES-1\", marker='o')\n",
        "        plt.plot(pl_module.psnr_scores_goes2, label=\"GOES-2\", marker='o')\n",
        "        plt.plot(pl_module.psnr_scores_avg,   label=\"Avg\", marker='o')\n",
        "        plt.title(\"Validation cPSNR over Epochs\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"cPSNR (dB)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True); plt.tight_layout(); plt.savefig(plot_path); plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BkY9BHVsL-OT"
      },
      "outputs": [],
      "source": [
        "class VisualizePredictionCallback(Callback):\n",
        "    def __init__(self, goes1_path, goes2_path, viirs_path, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.goes1_path = goes1_path\n",
        "        self.goes2_path = goes2_path\n",
        "        self.viirs_path = viirs_path\n",
        "        self.every_n_epochs = every_n_epochs\n",
        "\n",
        "        # Load visualization scaling values from JSON\n",
        "        with open(\"/content/radiance_visualization_ranges.json\", \"r\") as f:\n",
        "            self.ranges = json.load(f)\n",
        "\n",
        "        # Make output directory with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        self.output_dir = os.path.join(\"/content/checkpoints\", f\"visual_{timestamp}\")\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def scale_for_visualization(self, image, sensor_type=None):\n",
        "        p1 = np.percentile(image, 2)\n",
        "        p99 = np.percentile(image, 98)\n",
        "        return np.clip((image - p1) / (p99 - p1), 0, 1.0)\n",
        "\n",
        "\n",
        "    def load_image(self, path, band=1):\n",
        "        with rasterio.open(path) as src:\n",
        "            image = src.read(band).astype(np.float32)\n",
        "            mask = ~(np.isnan(image) | np.isinf(image))\n",
        "            if np.any(mask):\n",
        "                mean_val = image[mask].mean()\n",
        "                image = np.where(mask, image, mean_val)\n",
        "            else:\n",
        "                image = np.zeros_like(image)\n",
        "            return image\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch = trainer.current_epoch\n",
        "        if epoch % self.every_n_epochs != 0:\n",
        "            return\n",
        "\n",
        "        # Load GOES band 7 and VIIRS band 1\n",
        "        goes1_img = self.load_image(self.goes1_path, band=7)\n",
        "        goes2_img = self.load_image(self.goes2_path, band=7)\n",
        "        viirs_img = self.load_image(self.viirs_path, band=1)\n",
        "\n",
        "        # Convert to tensors\n",
        "        goes1_tensor = torch.from_numpy(goes1_img).unsqueeze(0).unsqueeze(0).to(pl_module.device)\n",
        "        goes2_tensor = torch.from_numpy(goes2_img).unsqueeze(0).unsqueeze(0).to(pl_module.device)\n",
        "\n",
        "        # Run prediction\n",
        "        with torch.no_grad():\n",
        "            pred1, pred2 = pl_module(goes1_tensor, goes2_tensor)\n",
        "            pred1 = pred1.squeeze().cpu().numpy()\n",
        "            pred2 = pred2.squeeze().cpu().numpy()\n",
        "\n",
        "        # Scale all images for visualization\n",
        "        g1_viz = self.scale_for_visualization(goes1_img, \"GOES\")\n",
        "        g2_viz = self.scale_for_visualization(goes2_img, \"GOES\")\n",
        "        viirs_viz = self.scale_for_visualization(viirs_img, \"VIIRS\")\n",
        "        pred1_viz = self.scale_for_visualization(pred1)\n",
        "        pred2_viz = self.scale_for_visualization(pred2)\n",
        "\n",
        "        # Plot all 4 images side by side\n",
        "        titles = [\"GOES-1\", \"GOES-2\", \"VIIRS (GT)\", \"Pred from G1\", \"Pred from G2\"]\n",
        "        images = [g1_viz, g2_viz, viirs_viz, pred1_viz, pred2_viz]\n",
        "        fig, axs = plt.subplots(1, 5, figsize=(24, 5))\n",
        "\n",
        "        for ax, img, title in zip(axs, images, titles):\n",
        "            im = ax.imshow(img, cmap=\"gray\", vmin=0, vmax=1.0)  # ⬅️ Changed to grayscale\n",
        "            ax.set_title(title)\n",
        "            ax.axis(\"off\")\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "        plt.suptitle(f\"Epoch {epoch}\", fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(self.output_dir, f\"epoch_{epoch:03d}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "        print(f\"✅ Saved visualization to {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOukz6qTN5GH"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AuA2vlo4GmnM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "pl_model = SuperResolutionModule(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dvUrezC519W-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40697a3-3236-42bb-8df5-c21d108deabb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOES-1 shape: torch.Size([1, 1, 100, 100])\n",
            "GOES-2 shape: torch.Size([1, 1, 100, 100])\n",
            "Output from GOES-1 shape: torch.Size([1, 1, 400, 400])\n",
            "Output from GOES-2 shape: torch.Size([1, 1, 400, 400])\n"
          ]
        }
      ],
      "source": [
        "# === Create dummy inputs ===\n",
        "goes1 = torch.randn(1, 1, 100, 100)  # GOES-1 image\n",
        "goes2 = torch.randn(1, 1, 100, 100)  # GOES-2 image\n",
        "\n",
        "# === Forward pass through the updated SwinIR wrapper ===\n",
        "pl_model.eval()\n",
        "with torch.no_grad():\n",
        "    out1, out2 = pl_model(goes1, goes2)\n",
        "\n",
        "# === Print shapes ===\n",
        "print(\"GOES-1 shape:\", goes1.shape)\n",
        "print(\"GOES-2 shape:\", goes2.shape)\n",
        "print(\"Output from GOES-1 shape:\", out1.shape)\n",
        "print(\"Output from GOES-2 shape:\", out2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QJecnx6tMBe_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac6b8c3bc6c94edbb6f6732220b60a04",
            "26f6a879087b4e2bbec6191986f642bf",
            "15a58820511a46449ee515a7580694ca",
            "50c59b3aa3dd43b2837b758ea6d4ab6d",
            "3bd63b46c8e644cab85d16871ac23531",
            "9947c561209d4df58ad6affbaaeba8b6",
            "2a22bbfffd884fc3b5cdf3331373cb9a",
            "6654d8aa11c3419da0682e7c7da034b2",
            "208ca814a1d8493da54f2ed48ba24979",
            "d4671e7e09424858a000cd4fa7e8f0bd",
            "a4f912a110c5466784c56259ebe03422"
          ]
        },
        "outputId": "2d5b63a5-6c5c-442f-b9e3-fb2fbb959b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type   | Params | Mode \n",
            "---------------------------------------------\n",
            "0 | model     | SwinIR | 6.2 M  | eval \n",
            "1 | criterion | L1Loss | 0      | train\n",
            "---------------------------------------------\n",
            "6.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.2 M     Total params\n",
            "24.680    Total estimated model params size (MB)\n",
            "1         Modules in train mode\n",
            "357       Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac6b8c3bc6c94edbb6f6732220b60a04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 000 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_000.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 001 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_001.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 002 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_002.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 003 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_003.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 004 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_004.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 005 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_005.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 006 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_006.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 007 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_007.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 008 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_008.png\n",
            "→ [0] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [1] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [2] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [3] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [4] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [5] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [6] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [7] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [8] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [9] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [10] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [11] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [12] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [13] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [14] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [15] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [16] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [17] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [18] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [19] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [20] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [21] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [22] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [23] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [24] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [25] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [26] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [27] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "→ [28] clipped_geo16.tif, clipped_geo18.tif, combined_clip.tif\n",
            "\n",
            "📈 Epoch 009 — GOES-1 PSNR: 80.00 | GOES-2 PSNR: 80.00 | Avg: 80.00 dB\n",
            "\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-05-04_12-58-57/epoch_009.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "# === DataModule ===\n",
        "datamodule = SatelliteDataModule(\n",
        "    csv_file=\"/content/drive/My Drive/superres_triplets.csv\",\n",
        "    batch_size=1,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# === Visualization Callback ===\n",
        "vis_callback = VisualizePredictionCallback(\n",
        "    goes1_path=\"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo16.tif\",\n",
        "    goes2_path=\"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo17.tif\",\n",
        "    viirs_path=\"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2020-11/2020-11-01_20-12/combined_clip.tif\",\n",
        "    every_n_epochs=1\n",
        ")\n",
        "\n",
        "\n",
        "# === PSNR Callback ===\n",
        "psnr_callback = PSNRValidationCallback(\n",
        "    vis_callback=vis_callback,\n",
        "    val_month_dir=\"/content/drive/My Drive/ONLY_TIF/ONLY_TIF/2023-02\",  # Folder with validation triplets\n",
        "    every_n_epochs=1\n",
        ")\n",
        "\n",
        "# === Logger ===\n",
        "logger = CSVLogger(\"logs\", name=\"swinir_superres\")\n",
        "\n",
        "# === Trainer ===\n",
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    precision=16,                # mixed precision\n",
        "    logger=logger,\n",
        "    gradient_clip_val=1.0,\n",
        "    callbacks=[psnr_callback, vis_callback],\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "# Wrap your SwinIR model\n",
        "pl_model = SuperResolutionModule(model)\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# === Fit the model ===\n",
        "trainer.fit(pl_model, datamodule=datamodule)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac6b8c3bc6c94edbb6f6732220b60a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f6a879087b4e2bbec6191986f642bf",
              "IPY_MODEL_15a58820511a46449ee515a7580694ca",
              "IPY_MODEL_50c59b3aa3dd43b2837b758ea6d4ab6d"
            ],
            "layout": "IPY_MODEL_3bd63b46c8e644cab85d16871ac23531"
          }
        },
        "26f6a879087b4e2bbec6191986f642bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9947c561209d4df58ad6affbaaeba8b6",
            "placeholder": "​",
            "style": "IPY_MODEL_2a22bbfffd884fc3b5cdf3331373cb9a",
            "value": "Epoch 9: 100%"
          }
        },
        "15a58820511a46449ee515a7580694ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6654d8aa11c3419da0682e7c7da034b2",
            "max": 1260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_208ca814a1d8493da54f2ed48ba24979",
            "value": 1260
          }
        },
        "50c59b3aa3dd43b2837b758ea6d4ab6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4671e7e09424858a000cd4fa7e8f0bd",
            "placeholder": "​",
            "style": "IPY_MODEL_a4f912a110c5466784c56259ebe03422",
            "value": " 1260/1260 [18:27&lt;00:00,  1.14it/s, v_num=3, train_loss=nan.0, train_psnr=nan.0]"
          }
        },
        "3bd63b46c8e644cab85d16871ac23531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "9947c561209d4df58ad6affbaaeba8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a22bbfffd884fc3b5cdf3331373cb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6654d8aa11c3419da0682e7c7da034b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208ca814a1d8493da54f2ed48ba24979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4671e7e09424858a000cd4fa7e8f0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f912a110c5466784c56259ebe03422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}