{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "323b7f97a28b4c479f6cf097b76a0c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_751dfaaf80064fc9a7d47eb74323c046",
              "IPY_MODEL_2b5b8afcb0ee4da8aa8af0dd06473c73",
              "IPY_MODEL_912b30516a6b4cc7a41ce2f1bb81adea"
            ],
            "layout": "IPY_MODEL_9db409348e6f48b1b16d31334cba83ce"
          }
        },
        "751dfaaf80064fc9a7d47eb74323c046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c483fed0794c3ca5490c4d32de7cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_8a2be469bf624ac5b5cec7aa4271429d",
            "value": "Epoch 14: 100%"
          }
        },
        "2b5b8afcb0ee4da8aa8af0dd06473c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756200d3b5b94a4ea4cc5903c222b9aa",
            "max": 420,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be2c87dcaa174e989261dc6b32867164",
            "value": 420
          }
        },
        "912b30516a6b4cc7a41ce2f1bb81adea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_562430929ebe41239c36bedaa526ee0e",
            "placeholder": "​",
            "style": "IPY_MODEL_b11ff0f8a29a40eb8e56697526c2e502",
            "value": " 420/420 [10:49&lt;00:00,  0.65it/s, v_num=17, train_loss=14.30]"
          }
        },
        "9db409348e6f48b1b16d31334cba83ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c2c483fed0794c3ca5490c4d32de7cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2be469bf624ac5b5cec7aa4271429d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "756200d3b5b94a4ea4cc5903c222b9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2c87dcaa174e989261dc6b32867164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "562430929ebe41239c36bedaa526ee0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11ff0f8a29a40eb8e56697526c2e502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#initaling things up"
      ],
      "metadata": {
        "id": "RwYAxWFrluoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1DeE7OK9eiWp",
        "outputId": "0fc0ec7f-5d8f-4c91-a834-7bce78f1c09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (1.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.2.0) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning==2.2.0) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->pytorch-lightning==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->pytorch-lightning==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.2.0) (3.10)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.14.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.7.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning==2.2.0\n",
        "!pip install rasterio\n",
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. environment flags (must be set *before* importing PL) -----------\n",
        "import os\n",
        "os.environ[\"PL_DISABLE_MIXED_IMPORTS\"] = \"1\"   # use *only* pytorch_lightning\n",
        "os.environ[\"TORCH_NAN_INF_CHECK\"]    = \"1\"     # raise if any NaN/Inf in fwd/bwd\n",
        "\n",
        "# --- 2. standard & utility packages ------------------------------------\n",
        "import sys, shutil, zipfile, csv\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import rasterio\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# --- 3. PyTorch core ----------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# --- 4. PyTorch Lightning (legacy namespace only) ----------------------\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "# --- 5. Colab conveniences (only if you’re in Colab) -------------------\n",
        "try:\n",
        "    from google.colab import drive, files\n",
        "except ImportError:\n",
        "    drive = files = None        # not running in Colab → ignore\n"
      ],
      "metadata": {
        "id": "2C3qmvW6ponp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "drive_tif_path = \"/content/drive/MyDrive/final_project/ONLY_TIF\"\n",
        "local_tif_path = \"/content/ONLY_TIF\"\n",
        "\n",
        "# If the folder already exists in local runtime, remove it first\n",
        "if os.path.exists(local_tif_path):\n",
        "    shutil.rmtree(local_tif_path)\n",
        "\n",
        "# Copy entire folder from Drive to local runtime\n",
        "shutil.copytree(drive_tif_path, local_tif_path)\n",
        "\n",
        "print(f\"Copied entire ONLY_TIF folder to: {local_tif_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftRu3-OpjpL-",
        "outputId": "461ebfad-7f0a-45ff-b0a9-d9b88a8eea48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Copied entire ONLY_TIF folder to: /content/ONLY_TIF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_triplet_csv(source_dir, output_csv_path):\n",
        "    data = []\n",
        "    id_counter = 1\n",
        "\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        files = [f for f in files if f.lower().endswith('.tif')]\n",
        "        if not files:\n",
        "            continue\n",
        "\n",
        "        goes1 = goes2 = viirs = None\n",
        "        for f in files:\n",
        "            f_lower = f.lower()\n",
        "            full_path = os.path.join(root, f)\n",
        "            rel_path = os.path.relpath(full_path, source_dir)\n",
        "\n",
        "            if 'geo16' in f_lower:\n",
        "                goes1 = rel_path\n",
        "            elif 'geo17' in f_lower:\n",
        "                goes2 = rel_path\n",
        "            elif 'geo18' in f_lower and goes2 is None:\n",
        "                goes2 = rel_path\n",
        "            elif 'combined' in f_lower:\n",
        "                viirs = rel_path\n",
        "\n",
        "        if goes1 and goes2 and viirs:\n",
        "            data.append({\n",
        "                'id': id_counter,\n",
        "                'goes1_path': os.path.join(source_dir, goes1),\n",
        "                'goes2_path': os.path.join(source_dir, goes2),\n",
        "                'viirs_path': os.path.join(source_dir, viirs),\n",
        "            })\n",
        "            id_counter += 1\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"✅ CSV saved to {output_csv_path} with {len(df)} records.\")\n",
        "\n",
        "# Define paths\n",
        "source_dir = \"/content/ONLY_TIF\"\n",
        "output_csv_path = \"/content/superres_triplets.csv\"\n",
        "\n",
        "make_triplet_csv(source_dir, output_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG6_e-YWjvL1",
        "outputId": "3d5d08ae-ef37-478d-cdfc-17579f9bef67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV saved to /content/superres_triplets.csv with 1260 records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cloning the repo and downloding the model"
      ],
      "metadata": {
        "id": "AVRoPu4cl4qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "clones"
      ],
      "metadata": {
        "id": "JMH-YD21pmKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sys.path.append(\"C:/Users/97254/OneDrive - post.bgu.ac.il/Desktop/code4finalproj/SwinIR-main\")\n",
        "# Clone the repo\n",
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "\n",
        "# Manually install necessary dependencies\n",
        "!pip install timm einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dQEtVD5ulqZY",
        "outputId": "f23b1372-8a42-4a52-d26e-8f94609a7f54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SwinIR' already exists and is not an empty directory.\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "zips"
      ],
      "metadata": {
        "id": "5btCTQvMpj-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i need you to zip SwinIR folder and download it to my pc\n",
        "\n",
        "!zip -r /content/SwinIR.zip /content/SwinIR\n",
        "\n",
        "files.download(\"/content/SwinIR.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "uhf9dPvDpOQW",
        "outputId": "e61f7a3b-f3ca-4bdf-eff2-7ebe28e4c602"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/SwinIR/ (stored 0%)\n",
            "  adding: content/SwinIR/models/ (stored 0%)\n",
            "  adding: content/SwinIR/models/network_swinir.py (deflated 80%)\n",
            "  adding: content/SwinIR/.git/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/info/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/info/exclude (deflated 28%)\n",
            "  adding: content/SwinIR/.git/config (deflated 30%)\n",
            "  adding: content/SwinIR/.git/description (deflated 14%)\n",
            "  adding: content/SwinIR/.git/refs/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/refs/heads/main (stored 0%)\n",
            "  adding: content/SwinIR/.git/HEAD (stored 0%)\n",
            "  adding: content/SwinIR/.git/objects/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/objects/info/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/objects/pack/pack-8cb5345fe53eb8fa954443bcf79443f61c566692.idx (deflated 6%)\n",
            "  adding: content/SwinIR/.git/objects/pack/pack-8cb5345fe53eb8fa954443bcf79443f61c566692.pack (deflated 0%)\n",
            "  adding: content/SwinIR/.git/index (deflated 56%)\n",
            "  adding: content/SwinIR/.git/packed-refs (deflated 20%)\n",
            "  adding: content/SwinIR/.git/branches/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/hooks/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/SwinIR/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/SwinIR/.git/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/SwinIR/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/SwinIR/.git/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/SwinIR/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/SwinIR/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/SwinIR/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/SwinIR/.git/logs/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/logs/refs/remotes/origin/HEAD (deflated 26%)\n",
            "  adding: content/SwinIR/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/SwinIR/.git/logs/refs/heads/main (deflated 26%)\n",
            "  adding: content/SwinIR/.git/logs/HEAD (deflated 26%)\n",
            "  adding: content/SwinIR/testsets/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/babyx3.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/butterflyx3.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/headx3.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/womanx3.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X3/birdx3.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/babyx2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/womanx2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/butterflyx2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/birdx2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X2/headx2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/butterflyx4.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/babyx4.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/birdx4.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/headx4.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X4/womanx4.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/butterflyx8.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/headx8.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/babyx8.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/womanx8.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/LR_bicubic/X8/birdx8.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/baby.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/butterfly.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/woman.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/bird.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set5/HR/head.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/McMaster/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/McMaster/15.tif (deflated 17%)\n",
            "  adding: content/SwinIR/testsets/McMaster/4.tif (deflated 24%)\n",
            "  adding: content/SwinIR/testsets/McMaster/14.tif (deflated 14%)\n",
            "  adding: content/SwinIR/testsets/McMaster/16.tif (deflated 10%)\n",
            "  adding: content/SwinIR/testsets/McMaster/5.tif (deflated 8%)\n",
            "  adding: content/SwinIR/testsets/McMaster/3.tif (deflated 13%)\n",
            "  adding: content/SwinIR/testsets/McMaster/10.tif (deflated 14%)\n",
            "  adding: content/SwinIR/testsets/McMaster/12.tif (deflated 21%)\n",
            "  adding: content/SwinIR/testsets/McMaster/2.tif (deflated 9%)\n",
            "  adding: content/SwinIR/testsets/McMaster/18.tif (deflated 18%)\n",
            "  adding: content/SwinIR/testsets/McMaster/11.tif (deflated 21%)\n",
            "  adding: content/SwinIR/testsets/McMaster/6.tif (deflated 12%)\n",
            "  adding: content/SwinIR/testsets/McMaster/17.tif (deflated 13%)\n",
            "  adding: content/SwinIR/testsets/McMaster/9.tif (deflated 17%)\n",
            "  adding: content/SwinIR/testsets/McMaster/13.tif (deflated 28%)\n",
            "  adding: content/SwinIR/testsets/McMaster/8.tif (deflated 31%)\n",
            "  adding: content/SwinIR/testsets/McMaster/7.tif (deflated 14%)\n",
            "  adding: content/SwinIR/testsets/McMaster/1.tif (deflated 6%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/building.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/chip.png (stored 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/comic3.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/ppt3.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/OST_009.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/0030.jpg (deflated 1%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/dped_crop00061.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/frog.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/Lincoln.png (deflated 1%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/oldphoto3.png (deflated 1%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/butterfly.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/oldphoto2.png (deflated 1%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/comic2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/oldphoto6.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/computer.png (deflated 2%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/pattern.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/tiger.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/painting.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/dog.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/00003.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/butterfly2.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/0014.jpg (deflated 1%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/comic1.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/foreman.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/RealSRSet+5images/ADE_val_00000114.jpg (deflated 2%)\n",
            "  adding: content/SwinIR/testsets/classic5/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/classic5/peppers.bmp (deflated 12%)\n",
            "  adding: content/SwinIR/testsets/classic5/lena.bmp (deflated 15%)\n",
            "  adding: content/SwinIR/testsets/classic5/boats.bmp (deflated 16%)\n",
            "  adding: content/SwinIR/testsets/classic5/barbara.bmp (deflated 12%)\n",
            "  adding: content/SwinIR/testsets/classic5/baboon.bmp (deflated 12%)\n",
            "  adding: content/SwinIR/testsets/Set12/ (stored 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/08.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/06.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/01.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/07.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/11.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/03.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/12.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/04.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/10.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/05.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/02.png (deflated 0%)\n",
            "  adding: content/SwinIR/testsets/Set12/09.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/ (stored 0%)\n",
            "  adding: content/SwinIR/figs/color_image_denoising.png (deflated 2%)\n",
            "  adding: content/SwinIR/figs/jepg_compress_artfact_reduction.png (deflated 2%)\n",
            "  adding: content/SwinIR/figs/ETH_BSRGAN.png (deflated 1%)\n",
            "  adding: content/SwinIR/figs/ETH_SwinIR-L.png (deflated 1%)\n",
            "  adding: content/SwinIR/figs/OST_009_crop_SwinIR-L.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/lightweight_image_sr.png (deflated 2%)\n",
            "  adding: content/SwinIR/figs/ETH_LR.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/OST_009_crop_BSRGAN.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/ETH_SwinIR.png (deflated 1%)\n",
            "  adding: content/SwinIR/figs/classic_image_sr_visual.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/ETH_realESRGAN.jpg (deflated 0%)\n",
            "  adding: content/SwinIR/figs/OST_009_crop_SwinIR.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/real_world_image_sr.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/OST_009_crop_LR.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/SwinIR_archi.png (deflated 2%)\n",
            "  adding: content/SwinIR/figs/classic_image_sr.png (deflated 2%)\n",
            "  adding: content/SwinIR/figs/OST_009_crop_realESRGAN.png (deflated 0%)\n",
            "  adding: content/SwinIR/figs/gray_image_denoising.png (deflated 2%)\n",
            "  adding: content/SwinIR/README.md (deflated 77%)\n",
            "  adding: content/SwinIR/LICENSE (deflated 65%)\n",
            "  adding: content/SwinIR/main_test_swinir.py (deflated 76%)\n",
            "  adding: content/SwinIR/download-weights.sh (deflated 86%)\n",
            "  adding: content/SwinIR/cog.yaml (deflated 44%)\n",
            "  adding: content/SwinIR/utils/ (stored 0%)\n",
            "  adding: content/SwinIR/utils/util_calculate_psnr_ssim.py (deflated 77%)\n",
            "  adding: content/SwinIR/model_zoo/ (stored 0%)\n",
            "  adding: content/SwinIR/model_zoo/README.md (deflated 5%)\n",
            "  adding: content/SwinIR/predict.py (deflated 72%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ddff362-5f69-4648-b6eb-a1b43ad21d97\", \"SwinIR.zip\", 62692792)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzips"
      ],
      "metadata": {
        "id": "jpoo_RCspk9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i need a code that unzips the SwinIR zip\n",
        "\n",
        "\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = \"/content/SwinIR.zip\"  # Replace with the actual path\n",
        "\n",
        "# Specify the directory to extract the contents to\n",
        "extract_dir = \"/content/SwinIR_extracted\"  # Replace with your desired directory\n",
        "\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Successfully extracted '{zip_file_path}' to '{extract_dir}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file '{zip_file_path}' not found.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Invalid zip file '{zip_file_path}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "Bhp6iuIOpcx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SwinIR\n",
        "\n",
        "# Download the pre-trained weights\n",
        "!mkdir -p experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth -P experiments/pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G1PUUJ4o7xx",
        "outputId": "3bd22944-a763-4062-89cf-a7bb6fa17ce3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SwinIR\n",
            "--2025-04-22 13:26:50--  https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/396770997/f3c0fbd1-d787-49f1-924a-8939e9a6707c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250422T132650Z&X-Amz-Expires=300&X-Amz-Signature=d92f7624602d2fe9777a776c799998ed47fa1affcd00e0be3d03bd2cff4b5d83&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-22 13:26:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/396770997/f3c0fbd1-d787-49f1-924a-8939e9a6707c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250422T132650Z&X-Amz-Expires=300&X-Amz-Signature=d92f7624602d2fe9777a776c799998ed47fa1affcd00e0be3d03bd2cff4b5d83&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67129861 (64M) [application/octet-stream]\n",
            "Saving to: ‘experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth.3’\n",
            "\n",
            "003_realSR_BSRGAN_D 100%[===================>]  64.02M   181MB/s    in 0.4s    \n",
            "\n",
            "2025-04-22 13:26:50 (181 MB/s) - ‘experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth.3’ saved [67129861/67129861]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset and loaders"
      ],
      "metadata": {
        "id": "pvaS4rT1lzui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SatelliteTripletDataset(Dataset):\n",
        "    def __init__(self, csv_file, json_range_path=\"radiance_visualization_ranges.json\"):\n",
        "        self.data_info = pd.read_csv(csv_file)\n",
        "\n",
        "        with open(json_range_path, \"r\") as f:\n",
        "            self.global_ranges = json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        record = self.data_info.iloc[idx]\n",
        "        goes1 = self.load_raw_radiance(record['goes1_path'])\n",
        "        goes2 = self.load_raw_radiance(record['goes2_path'])\n",
        "        viirs = self.load_raw_radiance(record['viirs_path'])\n",
        "        return (goes1, goes2), viirs\n",
        "\n",
        "    def load_raw_radiance(self, path):\n",
        "        filename = os.path.basename(path).lower()\n",
        "        is_viirs = \"viirs\" in filename or \"combined_clip\" in filename\n",
        "        sensor_type = \"VIIRS\" if is_viirs else \"GOES\"\n",
        "        band_index = 1 if is_viirs else 7\n",
        "\n",
        "        with rasterio.open(path) as src:\n",
        "            if src.count < band_index:\n",
        "                raise ValueError(f\"{path} does not contain band {band_index}\")\n",
        "            image = src.read(band_index).astype(np.float32)\n",
        "\n",
        "        # Handle NaN/Inf values\n",
        "        mask = ~(np.isnan(image) | np.isinf(image))\n",
        "        if not np.any(mask):\n",
        "            image = np.zeros_like(image)\n",
        "        else:\n",
        "            mean_val = image[mask].mean()\n",
        "            image = np.where(mask, image, mean_val)\n",
        "\n",
        "        # 🔁 Use global clipping range from JSON\n",
        "        p_low = self.global_ranges[sensor_type][\"p2\"]\n",
        "        p_high = self.global_ranges[sensor_type][\"p98\"]\n",
        "        image = np.clip(image, p_low, p_high)\n",
        "\n",
        "        return torch.from_numpy(image).unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "YgBtot1o0Dw5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SatelliteDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, csv_file, batch_size=4, num_workers=0, percentile_range=(2, 98)):\n",
        "        super().__init__()  # Correct super() call\n",
        "        self.csv_file = csv_file\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.percentile_range = percentile_range\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = SatelliteTripletDataset(\n",
        "            csv_file=self.csv_file,\n",
        "            json_range_path=\"/content/radiance_visualization_ranges.json\"\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=True\n",
        "        )"
      ],
      "metadata": {
        "id": "EmL1LDGf0DiL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# callbacks"
      ],
      "metadata": {
        "id": "6n6dVQcrtLiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class VisualizePredictionCallback(Callback):\n",
        "    def __init__(self, goes1_path, goes2_path, viirs_path, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.goes1_path = goes1_path\n",
        "        self.goes2_path = goes2_path\n",
        "        self.viirs_path = viirs_path\n",
        "        self.every_n_epochs = every_n_epochs\n",
        "\n",
        "        # Load visualization scaling values from JSON\n",
        "        with open(\"/content/radiance_visualization_ranges.json\", \"r\") as f:\n",
        "            self.ranges = json.load(f)\n",
        "\n",
        "        # Make output directory with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        self.output_dir = os.path.join(\"/content/checkpoints\", f\"visual_{timestamp}\")\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def scale_for_visualization(self, image, sensor_type=None):\n",
        "        p1 = np.percentile(image, 2)\n",
        "        p99 = np.percentile(image, 98)\n",
        "        return np.clip((image - p1) / (p99 - p1), 0, 1.0)\n",
        "\n",
        "    def load_image(self, path, band=1):\n",
        "        with rasterio.open(path) as src:\n",
        "            image = src.read(band).astype(np.float32)\n",
        "            mask = ~(np.isnan(image) | np.isinf(image))\n",
        "            if np.any(mask):\n",
        "                mean_val = image[mask].mean()\n",
        "                image = np.where(mask, image, mean_val)\n",
        "            else:\n",
        "                image = np.zeros_like(image)\n",
        "            return image\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch = trainer.current_epoch\n",
        "        if epoch % self.every_n_epochs != 0:\n",
        "            return\n",
        "\n",
        "        # Load GOES band 7 and VIIRS band 1\n",
        "        goes1_img = self.load_image(self.goes1_path, band=7)\n",
        "        goes2_img = self.load_image(self.goes2_path, band=7)\n",
        "        viirs_img = self.load_image(self.viirs_path, band=1)\n",
        "\n",
        "        # Convert to tensors\n",
        "        goes1_tensor = torch.from_numpy(goes1_img).unsqueeze(0).unsqueeze(0).to(pl_module.device)\n",
        "        goes2_tensor = torch.from_numpy(goes2_img).unsqueeze(0).unsqueeze(0).to(pl_module.device)\n",
        "\n",
        "        # Run prediction\n",
        "        with torch.no_grad():\n",
        "            predicted = pl_module(goes1_tensor, goes2_tensor).squeeze().cpu().numpy()\n",
        "\n",
        "        # Scale all images for visualization\n",
        "        g1_viz = self.scale_for_visualization(goes1_img, \"GOES\")\n",
        "        g2_viz = self.scale_for_visualization(goes2_img, \"GOES\")\n",
        "        viirs_viz = self.scale_for_visualization(viirs_img, \"VIIRS\")\n",
        "        pred_viz = self.scale_for_visualization(predicted, \"VIIRS\")\n",
        "\n",
        "        # Plot all 4 images side by side\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "        titles = [\"GOES-1\", \"GOES-2\", \"VIIRS (GT)\", \"Predicted\"]\n",
        "        images = [g1_viz, g2_viz, viirs_viz, pred_viz]\n",
        "\n",
        "        for ax, img, title in zip(axs, images, titles):\n",
        "            im = ax.imshow(img, cmap=\"gray\", vmin=0, vmax=1.0)  # ⬅️ Changed to grayscale\n",
        "            ax.set_title(title)\n",
        "            ax.axis(\"off\")\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "        plt.suptitle(f\"Epoch {epoch}\", fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(self.output_dir, f\"epoch_{epoch:03d}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "        print(f\"✅ Saved visualization to {save_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "utTJlgJltL01"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PSNRValidationCallback(Callback):\n",
        "    \"\"\"\n",
        "    Compute corrected PSNR (Kelvin metric) on a fixed month of triplets.\n",
        "    * uses the same helpers as the baseline script              (already defined)\n",
        "    * model gets raw GOES‑16 / GOES‑17(18) images (no bicubic up‑scale)\n",
        "    * VIIRS GT and model prediction are both high‑res → same shape\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    def __init__(self, vis_callback, val_month_dir, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.vis_callback   = vis_callback\n",
        "        self.val_month_dir  = val_month_dir\n",
        "        self.every_n_epochs = every_n_epochs\n",
        "\n",
        "        # read radiometric ranges once\n",
        "        with open(\"/content/radiance_visualization_ranges.json\") as f:\n",
        "            rng = json.load(f)\n",
        "        self.vi_min = rng[\"VIIRS\"][\"p2\"]\n",
        "        self.vi_rng = rng[\"VIIRS\"][\"p98\"] - self.vi_min\n",
        "\n",
        "        # collect (goes1, goes2, viirs) triplets once\n",
        "        self.triplets = self._collect_triplets(val_month_dir)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    @staticmethod\n",
        "    def _collect_triplets(root):\n",
        "        out = []\n",
        "        for cur, _, files in os.walk(root):\n",
        "            files = [f for f in files if f.lower().endswith(\".tif\")]\n",
        "            if not files:\n",
        "                continue\n",
        "            g1 = g2 = v = None\n",
        "            for f in files:\n",
        "                p  = os.path.join(cur, f)\n",
        "                lf = f.lower()\n",
        "                if \"geo16\" in lf:\n",
        "                    g1 = p\n",
        "                elif \"geo17\" in lf or (\"geo18\" in lf and g2 is None):\n",
        "                    g2 = p\n",
        "                elif \"combined\" in lf or \"viirs\" in lf:\n",
        "                    v  = p\n",
        "            if g1 and g2 and v:\n",
        "                out.append((g1, g2, v))\n",
        "        return out\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    @staticmethod\n",
        "    def _load_band(path):\n",
        "        is_viirs   = \"viirs\" in path.lower() or \"combined\" in path.lower()\n",
        "        band_index = 1 if is_viirs else 7           # VIIRS‑I4 or GOES‑7\n",
        "        with rasterio.open(path) as src:\n",
        "            img = src.read(band_index).astype(np.float32)\n",
        "        m = ~(np.isnan(img) | np.isinf(img))\n",
        "        return np.where(m, img, img[m].mean() if m.any() else 0.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def cpsnr(gt: np.ndarray, pred: np.ndarray, mask: np.ndarray) -> float:\n",
        "        \"\"\"Corrected PSNR (Kelvin): brightness‑bias + clear‑pixel mask.\"\"\"\n",
        "        diff = (gt - pred) * mask\n",
        "        b    = diff.sum() / (mask.sum() + 1e-8)                 # brightness bias\n",
        "        cmse = ((gt - pred + b) ** 2 * mask).sum() / (mask.sum() + 1e-8)\n",
        "        return -10.0 * np.log10(cmse + 1e-8)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch = trainer.current_epoch\n",
        "        if (epoch + 1) % self.every_n_epochs:\n",
        "            return\n",
        "\n",
        "        psnrs = []\n",
        "\n",
        "        for g1_path, g2_path, v_path in self.triplets:\n",
        "            g1   = self._load_band(g1_path)\n",
        "            g2   = self._load_band(g2_path)\n",
        "            vi   = self._load_band(v_path)              # H×W high‑res\n",
        "\n",
        "            # forward pass – model expects raw GOES (low‑res) inputs\n",
        "            pred = pl_module(torch.from_numpy(g1)[None, None].to(pl_module.device),\n",
        "                             torch.from_numpy(g2)[None, None].to(pl_module.device)\n",
        "                            ).squeeze().detach().cpu().numpy()   # H×W\n",
        "\n",
        "            # ------------- normalise to [0,1] with VIIRS range -------------\n",
        "            vi_n   = np.clip((vi   - self.vi_min) / self.vi_rng, 0, 1)\n",
        "            pred_n = np.clip((pred - self.vi_min) / self.vi_rng, 0, 1)\n",
        "\n",
        "            # ------------- clear‑pixel mask & Kelvin cPSNR -----------------\n",
        "            psnrs.append(self.cpsnr(vi_n, pred_n, np.ones_like(vi_n)))\n",
        "\n",
        "        mean_psnr = float(np.mean(psnrs))\n",
        "        if not hasattr(pl_module, \"psnr_scores\"):\n",
        "            pl_module.psnr_scores = []\n",
        "        pl_module.psnr_scores.append(mean_psnr)\n",
        "\n",
        "        # save a small curve in the same folder as visualisations\n",
        "        plot_path = os.path.join(self.vis_callback.output_dir,\n",
        "                                 f\"psnr_curve_epoch_{epoch:03d}.png\")\n",
        "        plt.figure(); plt.plot(pl_module.psnr_scores, marker='o')\n",
        "        plt.title(\"Validation cPSNR\"); plt.xlabel(\"epoch\"); plt.ylabel(\"dB\")\n",
        "        plt.grid(True); plt.tight_layout(); plt.savefig(plot_path); plt.close()\n",
        "\n",
        "        print(f\"📈  epoch {epoch:03d}  mean cPSNR: {mean_psnr:.2f} dB\")"
      ],
      "metadata": {
        "id": "gjbijHQntRu5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsAndCheckpointCallback(Callback):\n",
        "    \"\"\"tracks mean train‑loss & cPSNR, writes metrics.csv + loss plot,\n",
        "       saves weights when cPSNR > threshold\"\"\"\n",
        "\n",
        "    def __init__(self, vis_callback, cpsnr_threshold=10.5):\n",
        "        super().__init__()\n",
        "        self.dir = vis_callback.output_dir\n",
        "        self.cpsnr_threshold = cpsnr_threshold\n",
        "        self.loss_per_epoch = []\n",
        "        self.cpsnr_per_epoch = []\n",
        "        self._batch_losses = []\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "        try:\n",
        "            # Handle different output types\n",
        "            if isinstance(outputs, torch.Tensor):\n",
        "                loss_val = outputs.item()\n",
        "            elif isinstance(outputs, dict) and 'loss' in outputs:\n",
        "                loss_val = outputs['loss'].item()\n",
        "            else:\n",
        "                loss_val = float(outputs)  # Assume it's already a scalar\n",
        "\n",
        "            self._batch_losses.append(loss_val)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in on_train_batch_end: {e}\")\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        try:\n",
        "            # Calculate mean loss\n",
        "            if self._batch_losses:\n",
        "                loss_mean = float(np.mean(self._batch_losses))\n",
        "                self.loss_per_epoch.append(loss_mean)\n",
        "                self._batch_losses.clear()\n",
        "            else:\n",
        "                print(\"⚠️ No batch losses recorded this epoch\")\n",
        "                loss_mean = 0.0\n",
        "                self.loss_per_epoch.append(loss_mean)\n",
        "\n",
        "            # Get cPSNR if available\n",
        "            if hasattr(pl_module, 'psnr_scores') and pl_module.psnr_scores:\n",
        "                cpsnr_mean = float(pl_module.psnr_scores[-1])\n",
        "            else:\n",
        "                print(\"⚠️ No psnr_scores available - initializing\")\n",
        "                if not hasattr(pl_module, 'psnr_scores'):\n",
        "                    pl_module.psnr_scores = []\n",
        "                cpsnr_mean = 0.0\n",
        "                pl_module.psnr_scores.append(cpsnr_mean)\n",
        "\n",
        "            self.cpsnr_per_epoch.append(cpsnr_mean)\n",
        "\n",
        "            # Save checkpoint if cPSNR is above threshold\n",
        "            if cpsnr_mean > self.cpsnr_threshold:\n",
        "                fname = f\"best_cpsnr_epoch_{trainer.current_epoch:03d}.pth\"\n",
        "                torch.save(pl_module.state_dict(), os.path.join(self.dir, fname))\n",
        "                print(f\"💾 Saved checkpoint – cPSNR {cpsnr_mean:.2f} dB\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in on_train_epoch_end: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    def on_fit_end(self, trainer, pl_module):\n",
        "        try:\n",
        "            # Save metrics to CSV\n",
        "            csv_path = os.path.join(self.dir, \"metrics.csv\")\n",
        "            with open(csv_path, \"w\", newline=\"\") as f:\n",
        "                w = csv.writer(f)\n",
        "                w.writerow([\"epoch\", \"train_loss\", \"cpsnr_db\"])\n",
        "                for e, l, p in zip(range(len(self.loss_per_epoch)),\n",
        "                                  self.loss_per_epoch,\n",
        "                                  self.cpsnr_per_epoch):\n",
        "                    w.writerow([e, f\"{l:.6f}\", f\"{p:.4f}\"])\n",
        "            print(f\"✅ Metrics written → {csv_path}\")\n",
        "\n",
        "            # Plot loss curve\n",
        "            plt.figure()\n",
        "            plt.plot(self.loss_per_epoch, marker=\"o\")\n",
        "            plt.title(\"Mean Training Loss per Epoch\")\n",
        "            plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(self.dir, \"loss_curve.png\"))\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in on_fit_end: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()"
      ],
      "metadata": {
        "id": "n-RO7U96cnIf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modeling SwinIR"
      ],
      "metadata": {
        "id": "PMIPswffr6Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sys.path.append('/content/SwinIR')  # Add the repository to path\n",
        "from models.network_swinir import SwinIR\n",
        "\n",
        "def create_modified_swinir(\n",
        "    pretrained_path,\n",
        "    in_chans=2,   # GOES-16 + GOES-17/18\n",
        "    out_chans=1,  # VIIRS\n",
        "    img_size=100  # Your image size\n",
        "):\n",
        "    # Find the largest window size that evenly divides the image size\n",
        "    def find_divisible_window_size(img_size, max_window_size=16):\n",
        "        for window_size in range(max_window_size, 0, -1):\n",
        "            if img_size % window_size == 0:\n",
        "                return window_size\n",
        "        return 1  # Fallback to 1 if no divisible size found\n",
        "\n",
        "    window_size = find_divisible_window_size(img_size)\n",
        "\n",
        "    print(f\"Adjusted window size to: {window_size}\")\n",
        "\n",
        "    model = SwinIR(\n",
        "        upscale=4,            # 4x upscaling\n",
        "        in_chans=in_chans,    # Input channels\n",
        "        out_chans=out_chans,  # Output channels\n",
        "        img_size=img_size,    # Set to your image size (100x100)\n",
        "        window_size=window_size,  # Dynamically calculated window size\n",
        "        img_range=1.,         # Normalized range [0,1]\n",
        "        depths=[6, 6, 6, 6, 6, 6],  # Keep original depth\n",
        "        embed_dim=180,        # Keep original embedding dimension\n",
        "        num_heads=[6, 6, 6, 6, 6, 6],  # Keep original number of heads\n",
        "        mlp_ratio=2,          # Keep original MLP ratio\n",
        "        upsampler='nearest+conv',  # Use nearest+conv for real-world SR\n",
        "        resi_connection='1conv'  # Keep original residual connection\n",
        "    )\n",
        "\n",
        "    # Rest of the weight loading code remains the same\n",
        "    pretrained = torch.load(pretrained_path, map_location='cpu')\n",
        "\n",
        "    if 'params_ema' in pretrained:\n",
        "        pretrained = pretrained['params_ema']\n",
        "    elif 'params' in pretrained:\n",
        "        pretrained = pretrained['params']\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "\n",
        "    pretrained_dict = {k: v for k, v in pretrained.items()\n",
        "                       if k in model_dict and v.shape == model_dict[k].shape}\n",
        "\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "\n",
        "    # Adapt input layer if needed\n",
        "    if in_chans != 3:\n",
        "        if 'conv_first.weight' in pretrained:\n",
        "            with torch.no_grad():\n",
        "                original_weight = pretrained['conv_first.weight']\n",
        "                if in_chans == 2:\n",
        "                    new_weight = original_weight[:, :2, :, :]\n",
        "                    model.conv_first.weight.data = new_weight\n",
        "\n",
        "    # ‑‑‑ adapt conv_last if you load RGB weights ‑‑‑\n",
        "    if out_chans == 1 and 'conv_last.weight' in pretrained:\n",
        "        with torch.no_grad():\n",
        "            w_rgb = pretrained['conv_last.weight']      # shape [3, C, 3, 3]\n",
        "            model.conv_last.weight.data = w_rgb.mean(dim=0, keepdim=True)\n",
        "\n",
        "    print(f\"Loaded {len(pretrained_dict)}/{len(model_dict)} parameters from pre-trained model\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZOp-80ES1Z4u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# experiment with M"
      ],
      "metadata": {
        "id": "crca5QWM-xSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the modified SwinIR model\n",
        "# Usage\n",
        "model = create_modified_swinir(\n",
        "    pretrained_path='experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth',\n",
        "    in_chans=2,   # GOES-16 + GOES-17/18\n",
        "    out_chans=1,  # VIIRS\n",
        "    img_size=100  # Your image size\n",
        ")\n",
        "\n",
        "# Convert to Lightning module for training\n",
        "class SwinIRLightningModule(pl.LightningModule):\n",
        "    def __init__(self, model, lr=1e-4):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.L1Loss()\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, goes1, goes2):\n",
        "        x = torch.cat((goes1, goes2), dim=1)  # Combine channels: [B, 2, H, W]\n",
        "        return self.model(x)  # [B, 1, H*4, W*4]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (goes1, goes2), viirs = batch\n",
        "        output = self(goes1, goes2)\n",
        "\n",
        "        # Ensure same spatial dimensions for loss calculation\n",
        "        if output.shape[2:] != viirs.shape[2:]:\n",
        "            output = F.interpolate(output, size=viirs.shape[2:],\n",
        "                                  mode='bilinear', align_corners=False)\n",
        "\n",
        "        loss = self.criterion(output, viirs)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "# Create Lightning module\n",
        "pl_model = SwinIRLightningModule(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-QUWeZI31d7v",
        "outputId": "ec83e0f1-ca1b-401f-d891-f2a3f6b5dba2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted window size to: 10\n",
            "Loaded 459/552 parameters from pre-trained model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create visualization callback\n",
        "vis_callback = VisualizePredictionCallback(\n",
        "    goes1_path=\"/content/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo16.tif\",\n",
        "    goes2_path=\"/content/ONLY_TIF/2020-11/2020-11-01_20-12/clipped_geo17.tif\",\n",
        "    viirs_path=\"/content/ONLY_TIF/2020-11/2020-11-01_20-12/combined_clip.tif\",\n",
        "    every_n_epochs=1  # Visualize every epoch\n",
        ")\n",
        "\n",
        "# Create PSNR validation callback\n",
        "psnr_callback = PSNRValidationCallback(\n",
        "    vis_callback=vis_callback,\n",
        "    val_month_dir=\"/content/ONLY_TIF/2023-02\",  # Directory containing validation month data\n",
        "    every_n_epochs=1  # Compute PSNR every epoch\n",
        ")\n",
        "\n",
        "metrics_ckpt_cb = MetricsAndCheckpointCallback(vis_callback)\n",
        "\n",
        "# Data module\n",
        "datamodule = SatelliteDataModule(\n",
        "    csv_file=\"/content/superres_triplets.csv\",\n",
        "    batch_size=3\n",
        ")\n",
        "\n",
        "\n",
        "# Create trainer with callbacks\n",
        "trainer = Trainer(\n",
        "    max_epochs=15,\n",
        "    accelerator='gpu',\n",
        "    devices=1,\n",
        "    precision=32,  # Use mixed precision for efficiency\n",
        "    log_every_n_steps=10,\n",
        "    callbacks=[psnr_callback, vis_callback, metrics_ckpt_cb]  # Add callbacks here\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.fit(pl_model, datamodule=datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "323b7f97a28b4c479f6cf097b76a0c68",
            "751dfaaf80064fc9a7d47eb74323c046",
            "2b5b8afcb0ee4da8aa8af0dd06473c73",
            "912b30516a6b4cc7a41ce2f1bb81adea",
            "9db409348e6f48b1b16d31334cba83ce",
            "c2c483fed0794c3ca5490c4d32de7cf6",
            "8a2be469bf624ac5b5cec7aa4271429d",
            "756200d3b5b94a4ea4cc5903c222b9aa",
            "be2c87dcaa174e989261dc6b32867164",
            "562430929ebe41239c36bedaa526ee0e",
            "b11ff0f8a29a40eb8e56697526c2e502"
          ]
        },
        "id": "K0Jz_dFA1h4H",
        "outputId": "7631c480-014c-42bb-9403-b8c7f19539c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type   | Params\n",
            "-------------------------------------\n",
            "0 | model     | SwinIR | 11.7 M\n",
            "1 | criterion | L1Loss | 0     \n",
            "-------------------------------------\n",
            "11.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.7 M    Total params\n",
            "46.969    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "323b7f97a28b4c479f6cf097b76a0c68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈  epoch 000  mean cPSNR: 11.17 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_000.png\n",
            "💾 Saved checkpoint – cPSNR 11.17 dB\n",
            "📈  epoch 001  mean cPSNR: 10.50 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_001.png\n",
            "💾 Saved checkpoint – cPSNR 10.50 dB\n",
            "📈  epoch 002  mean cPSNR: 8.48 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_002.png\n",
            "📈  epoch 003  mean cPSNR: 10.77 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_003.png\n",
            "💾 Saved checkpoint – cPSNR 10.77 dB\n",
            "📈  epoch 004  mean cPSNR: 9.27 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_004.png\n",
            "📈  epoch 005  mean cPSNR: 9.40 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_005.png\n",
            "📈  epoch 006  mean cPSNR: 10.97 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_006.png\n",
            "💾 Saved checkpoint – cPSNR 10.97 dB\n",
            "📈  epoch 007  mean cPSNR: 9.81 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_007.png\n",
            "📈  epoch 008  mean cPSNR: 9.54 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_008.png\n",
            "📈  epoch 009  mean cPSNR: 10.31 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_009.png\n",
            "📈  epoch 010  mean cPSNR: 9.95 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_010.png\n",
            "📈  epoch 011  mean cPSNR: 9.25 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_011.png\n",
            "📈  epoch 012  mean cPSNR: 11.70 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_012.png\n",
            "💾 Saved checkpoint – cPSNR 11.70 dB\n",
            "📈  epoch 013  mean cPSNR: 11.78 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_013.png\n",
            "💾 Saved checkpoint – cPSNR 11.78 dB\n",
            "📈  epoch 014  mean cPSNR: 11.81 dB\n",
            "✅ Saved visualization to /content/checkpoints/visual_2025-04-22_14-04-18/epoch_014.png\n",
            "💾 Saved checkpoint – cPSNR 11.81 dB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Metrics written → /content/checkpoints/visual_2025-04-22_14-04-18/metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/checkpoints', 'zip', '/content/checkpoints')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content/checkpoints.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MjUTseQkyXYL",
        "outputId": "91f18514-b412-4408-e2ef-1e3186d1f89f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2b961ee-a771-4c53-ae38-b853b0214ff8\", \"checkpoints.zip\", 369316171)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}